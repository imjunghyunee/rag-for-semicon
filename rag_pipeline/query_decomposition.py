from __future__ import annotations
from typing import List, Dict, Any, Optional
from rag_pipeline import utils, retrievers, config
from langchain.schema import Document


def decompose_query(original_query: str, max_subquestions: int = 5) -> List[str]:
    """
    ë³µì¡í•œ ì§ˆë¬¸ì„ ë” ì‘ì€ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´í•©ë‹ˆë‹¤.

    Args:
        original_query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
        max_subquestions: ìµœëŒ€ í•˜ìœ„ ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        í•˜ìœ„ ì§ˆë¬¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    """
    try:
        response = utils.client.chat.completions.create(
            model=config.OPENAI_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": f"""You are an expert in semiconductor physics who excels at breaking down complex questions into simpler, manageable sub-questions.

                                    When given a complex question, break it down into {max_subquestions} or fewer sub-questions that:
                                    1. Are simpler and more focused than the original question
                                    2. Build upon each other logically
                                    3. When answered together, provide comprehensive information to solve the original question
                                    4. Are specific to semiconductor physics domain

                                    Examples of good decomposition:
                                    - Complex: "How does temperature affect both carrier concentration and mobility in silicon devices?"
                                    - Sub-questions:
                                    1. What is the relationship between temperature and intrinsic carrier concentration in silicon?
                                    2. How does temperature affect electron and hole mobility in silicon?
                                    3. What are the combined effects on device performance?

                                    Format your response as a numbered list:
                                    1. [First sub-question]
                                    2. [Second sub-question]
                                    ...

                                    Respond with ONLY the numbered list of sub-questions.""",
                },
                {
                    "role": "user",
                    "content": f"Let's break down this complex semiconductor physics question: {original_query}",
                },
            ],
            max_tokens=5000,
            temperature=0.3,
        )

        response_text = response.choices[0].message.content.strip()

        # Parse numbered list into individual questions
        subquestions = []
        lines = response_text.split("\n")

        for line in lines:
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith("-")):
                # Remove numbering and clean up
                if ". " in line:
                    question = line.split(". ", 1)[1].strip()
                elif "- " in line:
                    question = line.split("- ", 1)[1].strip()
                else:
                    question = line.strip()

                if question and len(question) > 10:  # Filter out very short responses
                    subquestions.append(question)

        # Fallback if no valid sub-questions generated
        if not subquestions:
            print(
                "Warning: No valid sub-questions generated, creating fallback questions"
            )
            # Simple fallback strategy
            subquestions = [
                f"What are the fundamental concepts related to: {original_query}?",
                f"What are the key factors that influence: {original_query}?",
                f"How can we analyze or solve: {original_query}?",
            ]

        # Limit to max_subquestions
        return subquestions[:max_subquestions]

    except Exception as e:
        print(f"Error in query decomposition: {e}")
        # Return fallback questions
        return [
            f"What are the basic principles underlying this question: {original_query}?",
            f"What specific factors should be considered for: {original_query}?",
        ]


def process_subquestion(
    subquestion: str,
    retrieval_type: Optional[str] = None,
    hybrid_weights: Optional[List[float]] = None,
    previous_results: Optional[List[Dict[str, Any]]] = None,
) -> Dict[str, Any]:
    """
    í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì´ì „ ë‹¨ê³„ì˜ ì§ˆë¬¸-ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        subquestion: ì²˜ë¦¬í•  í•˜ìœ„ ì§ˆë¬¸
        retrieval_type: ê²€ìƒ‰ íƒ€ì… (hyde, summary, summary_mean, None)
        hybrid_weights: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        previous_results: ì´ì „ ë‹¨ê³„ë“¤ì˜ ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

    Returns:
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ë‹µë³€ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    current_step = len(previous_results) + 1 if previous_results else 1
    print(f"   Processing Step {current_step} subquestion: {subquestion}")
    
    # 1) ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ê²€ìƒ‰ í•¨ìˆ˜ ì„ íƒ
    if retrieval_type == "hyde" and hybrid_weights:
        context_docs, explanation = retrievers.hyde_hybrid_retrieve(
            subquestion, weights=hybrid_weights
        )
    elif retrieval_type == "hyde":
        context_docs, explanation = retrievers.hyde_retrieve(subquestion)
    elif retrieval_type == "summary" and hybrid_weights:
        context_docs, explanation = retrievers.summary_hybrid_retrieve(
            subquestion, weights=hybrid_weights
        )
    elif retrieval_type == "summary":
        context_docs, explanation = retrievers.summary_retrieve(subquestion)
    elif retrieval_type == "summary_mean" and hybrid_weights:
        context_docs, explanation = retrievers.summary_mean_retrieve_hybrid(
            subquestion, weights=hybrid_weights
        )
    elif retrieval_type == "summary_mean":
        context_docs, explanation = retrievers.summary_mean_retrieve(subquestion)
    elif hybrid_weights:
        context_docs = retrievers.vectordb_hybrid_retrieve(
            subquestion, weights=hybrid_weights
        )
        explanation = ""
    else:
        context_docs = retrievers.vectordb_retrieve(subquestion)
        explanation = ""

    # 2) ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    if isinstance(context_docs, tuple):
        context_docs = context_docs[0]  # tupleì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë¬¸ì„œë“¤

    context_contents = [
        doc.page_content for doc in context_docs if isinstance(doc, Document)
    ]
    retrieved_context = "\n\n---\n\n".join(context_contents)

    # 3) ì´ì „ ë‹¨ê³„ë“¤ì˜ Q&A ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìš”êµ¬ì‚¬í•­ 2 í•µì‹¬ ë¶€ë¶„)
    previous_qa_contexts = []
    if previous_results:
        for i, result in enumerate(previous_results, 1):
            # ê° ì´ì „ ë‹¨ê³„ì˜ Q&Aë¥¼ ëª…í™•íˆ êµ¬ì¡°í™”
            qa_pair = f"=== Step {i} ===\nQuestion: {result['question']}\nAnswer: {result['answer']}"
            previous_qa_contexts.append(qa_pair)
        
        print(f"   ğŸ“š Including Q&A context from {len(previous_results)} previous steps")
    
    previous_qa_context = "\n\n".join(previous_qa_contexts)

    # 4) ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±: ì´ì „ Q&A + í˜„ì¬ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ (ìš”êµ¬ì‚¬í•­ 2 êµ¬í˜„)
    context_sections = []
    
    if previous_qa_context:
        context_sections.append(f"=== Previous Steps Q&A ===\n{previous_qa_context}")
    
    if retrieved_context:
        context_sections.append(f"=== Step {current_step} Retrieved Documents ===\n{retrieved_context}")
    
    full_context = "\n\n".join(context_sections)

    # 5) ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ê´€ë¦¬ ë° í’ˆì§ˆ ë³´ì¥
    max_context_length = 25000  # ì•ˆì „í•œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
    if len(full_context) > max_context_length:
        print(f"   âš ï¸ Context length ({len(full_context)}) exceeds limit, applying intelligent truncation")
        
        # ì´ì „ Q&AëŠ” ìµœëŒ€í•œ ë³´ì¡´í•˜ê³  ê²€ìƒ‰ ë¬¸ì„œë¥¼ ì¡°ì •
        if previous_qa_context:
            # ì´ì „ Q&A í¬ê¸° í™•ì¸
            qa_context_size = len(previous_qa_context) + 500  # ì—¬ìœ ë¶„
            remaining_space = max_context_length - qa_context_size
            
            if remaining_space > 1000:  # ì¶©ë¶„í•œ ê³µê°„ì´ ìˆìœ¼ë©´
                truncated_retrieved = retrieved_context[:remaining_space] + "\n\n[Retrieved context truncated due to length]"
                full_context = f"=== Previous Steps Q&A ===\n{previous_qa_context}\n\n=== Step {current_step} Retrieved Documents ===\n{truncated_retrieved}"
            else:
                # ê³µê°„ì´ ë¶€ì¡±í•˜ë©´ ì´ì „ Q&Aë„ ìµœì‹  ë¶€ë¶„ë§Œ ìœ ì§€
                recent_qa_limit = max_context_length // 2
                truncated_qa = previous_qa_context[-recent_qa_limit:] + "\n[Previous Q&A truncated, showing recent parts only]"
                truncated_retrieved = retrieved_context[:max_context_length//2] + "\n[Retrieved context truncated]"
                full_context = f"=== Previous Steps Q&A (Recent) ===\n{truncated_qa}\n\n=== Step {current_step} Retrieved Documents ===\n{truncated_retrieved}"
        else:
            # ì´ì „ Q&Aê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ ë¬¸ì„œë§Œ ì¡°ì •
            full_context = retrieved_context[:max_context_length] + "\n\n[Retrieved context truncated due to length]"
        
        print(f"   ğŸ“ Final context length: {len(full_context)} characters")

    # 6) í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (ìš”êµ¬ì‚¬í•­ 2: ì „ì²´ ì»¨í…ìŠ¤íŠ¸ í™œìš©)
    print(f"   ğŸ¤– Generating answer for Step {current_step} with full context...")
    answer = utils.generate_llm_answer(subquestion, full_context)

    print(f"   âœ… Step {current_step} completed (answer length: {len(answer)} chars)")

    return {
        "question": subquestion,
        "retrieved_context": retrieved_context,  # í˜„ì¬ ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë§Œ
        "previous_context": previous_qa_contexts,  # ì´ì „ ë‹¨ê³„ë“¤ì˜ Q&A
        "full_context": full_context,  # ì´ì „ ë‹¨ê³„ + í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ (ìš”êµ¬ì‚¬í•­ 2)
        "answer": answer,
        "explanation": explanation,
        "context_docs": context_docs,
        "step_number": current_step,  # ë””ë²„ê¹…ìš© ë‹¨ê³„ ë²ˆí˜¸ ì¶”ê°€
    }


def aggregate_subquestion_results(
    original_query: str, subquestion_results: List[Dict[str, Any]]
) -> str:
    """
    í•˜ìœ„ ì§ˆë¬¸ë“¤ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì›ë³¸ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        original_query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
        subquestion_results: í•˜ìœ„ ì§ˆë¬¸ë“¤ì˜ ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

    Returns:
        ìµœì¢… ì¢…í•© ë‹µë³€
    """
    if not subquestion_results:
        return f"Unable to process the complex question: {original_query}"

    # ëª¨ë“  í•˜ìœ„ ì§ˆë¬¸ì˜ ì»¨í…ìŠ¤íŠ¸ì™€ ë‹µë³€ì„ ì¢…í•©
    combined_answers = ""
    all_retrieved_contexts = []

    for i, result in enumerate(subquestion_results, 1):
        combined_answers += (
            f"{i}. Q: {result['question']}\n   A: {result['answer']}\n\n"
        )

        # ê° ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë§Œ ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€)
        if result.get("retrieved_context"):
            all_retrieved_contexts.append(
                f"=== Sub-question {i} Context ===\n{result['retrieved_context']}"
            )

    # ì „ì²´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
    combined_retrieved_context = "\n\n".join(all_retrieved_contexts)

    try:
        final_answer = (
            utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert in semiconductor physics who excels at synthesizing complex information to provide comprehensive answers.

                                    Based on sub-question answers and context, provide a comprehensive, well-structured final answer that:
                                    1. Synthesizes information from all sub-questions
                                    2. Addresses the original question directly and completely
                                    3. Is technically accurate for semiconductor physics domain
                                    4. Includes relevant details and explanations
                                    5. Shows how the sub-answers connect to form the complete solution

                                    Structure your response clearly with proper reasoning and conclusions.""",
                    },
                    {
                        "role": "user",
                        "content": f"""Original Complex Question: {original_query}

                                    Sequential sub-questions and their answers:
                                    {combined_answers}

                                    Retrieved context from all searches:
                                    {combined_retrieved_context}

                                    Please provide a comprehensive final answer to the original question.""",
                    },
                ],
                max_tokens=2000,
                temperature=0.2,
            )
            .choices[0]
            .message.content.strip()
        )

        return final_answer

    except Exception as e:
        print(f"Error in final answer generation: {e}")
        # Fallback: simple concatenation
        return f"Based on the sequential analysis of sub-questions:\n\n{combined_answers}\n\nThese findings address the original question: {original_query}"


def process_complex_query(
    original_query: str,
    retrieval_type: Optional[str] = None,
    hybrid_weights: Optional[List[float]] = None,
    max_subquestions: int = 5,
) -> Dict[str, Any]:
    """
    ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì „ì²´ ì²˜ë¦¬ ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    í•˜ìœ„ ì§ˆë¬¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ê° ë‹¨ê³„ì—ì„œ ì´ì „ ë‹¨ê³„ì˜ ì§ˆë¬¸-ë‹µë³€ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•©ë‹ˆë‹¤.

    Args:
        original_query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
        retrieval_type: ê²€ìƒ‰ íƒ€ì…
        hybrid_weights: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        max_subquestions: ìµœëŒ€ í•˜ìœ„ ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        ìµœì¢… ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    print(f"ğŸ” Processing complex query: {original_query}")

    try:
        # 1. ì§ˆë¬¸ ë¶„í•´ (ìš”êµ¬ì‚¬í•­ 1)
        print("ğŸ“ Step 1: Decomposing query into sub-questions...")
        subquestions = decompose_query(original_query, max_subquestions)

        if not subquestions:
            print("âš ï¸ Warning: No sub-questions generated, falling back to simple processing")
            return {
                "original_query": original_query,
                "subquestions": [original_query],
                "subquestion_results": [],
                "final_answer": f"Unable to decompose query. Processing as simple query: {original_query}",
                "combined_context": "",
                "all_context_docs": [],
            }

        print(f"ğŸ“‹ Generated {len(subquestions)} sub-questions:")
        for i, sq in enumerate(subquestions, 1):
            print(f"  {i}. {sq}")

        # 2. ê° í•˜ìœ„ ì§ˆë¬¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (ìš”êµ¬ì‚¬í•­ 1 & 2)
        print("âš¡ Step 2: Processing sub-questions sequentially with cumulative context...")
        subquestion_results = []

        for i, subquestion in enumerate(subquestions, 1):
            try:
                print(f"\nğŸ”„ Processing Step {i}/{len(subquestions)}")
                print(f"   Question: {subquestion}")

                # ìš”êµ¬ì‚¬í•­ 2: ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ì „ë‹¬í•˜ì—¬ cumulative context êµ¬ì„±
                result = process_subquestion(
                    subquestion,
                    retrieval_type,
                    hybrid_weights,
                    previous_results=subquestion_results,  # ëˆ„ì ëœ ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼
                )

                subquestion_results.append(result)

                print(f"   âœ… Step {i} completed successfully")
                print(f"   ğŸ“Š Context included: {len(result.get('previous_context', []))} previous Q&A pairs + current retrieval")

            except Exception as e:
                print(f"   âŒ Error processing Step {i}: {e}")
                # ì—ëŸ¬ê°€ ë°œìƒí•œ í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ì„œë„ ê¸°ë³¸ ê²°ê³¼ ì¶”ê°€
                error_result = {
                    "question": subquestion,
                    "retrieved_context": "",
                    "previous_context": [],
                    "full_context": "",
                    "answer": f"Error processing this sub-question: {str(e)}",
                    "explanation": "",
                    "context_docs": [],
                    "step_number": i,
                }
                subquestion_results.append(error_result)

        # 3. ê²°ê³¼ ì¢…í•©
        print("Step 3: Aggregating sequential results...")
        try:
            final_answer = aggregate_subquestion_results(
                original_query, subquestion_results
            )
        except Exception as e:
            print(f"Error in aggregation: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ë‹µë³€ ì¡°í•©
            answers = [
                result["answer"] for result in subquestion_results if result["answer"]
            ]
            final_answer = (
                f"Based on the sequential sub-questions analysis:\n\n"
                + "\n\n".join(answers)
            )

        # ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í†µí•©
        all_retrieved_contexts = []
        all_context_docs = []

        for i, result in enumerate(subquestion_results, 1):
            if result.get("retrieved_context"):
                all_retrieved_contexts.append(
                    f"=== Step {i} Retrieved Context ===\n{result['retrieved_context']}"
                )
            if result.get("context_docs"):
                all_context_docs.extend(result["context_docs"])

        combined_context = "\n\n".join(all_retrieved_contexts)

        # ëˆ„ì  Q&A ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ë””ë²„ê¹… ë° ì¶”ì ìš©)
        cumulative_qa_parts = []
        for i, result in enumerate(subquestion_results, 1):
            cumulative_qa_parts.append(f"Step {i} Q: {result['question']}\nStep {i} A: {result['answer']}")
        cumulative_qa_context = "\n\n".join(cumulative_qa_parts)

        print("âœ… Sequential complex query processing completed successfully")
        print(f"ğŸ“ˆ Total steps processed: {len(subquestion_results)}")

        return {
            "original_query": original_query,
            "subquestions": subquestions,
            "subquestion_results": subquestion_results,
            "final_answer": final_answer,
            "combined_context": combined_context,
            "all_context_docs": all_context_docs,
            "cumulative_qa_context": cumulative_qa_context,  # ì „ì²´ Q&A ì§„í–‰ ê³¼ì •
            "processing_summary": f"Processed {len(subquestions)} sub-questions with cumulative context",
        }

    except Exception as e:
        print(f"ğŸ’¥ Critical error in complex query processing: {e}")
        # ìµœì¢… í´ë°±
        return {
            "original_query": original_query,
            "subquestions": [original_query],
            "subquestion_results": [],
            "final_answer": f"Error processing complex query: {str(e)}. Please try rephrasing your question.",
            "combined_context": "",
            "all_context_docs": [],
            "cumulative_qa_context": "",
            "processing_summary": "Error occurred during processing",
        }


def process_complex_query_with_expansion(
    original_query: str,
    content_docs: List[Document],
    example_docs: List[Dict[str, Any]],
    retrieval_type: Optional[str] = None,
    hybrid_weights: Optional[List[float]] = None,
    max_subquestions: int = 5,
) -> Dict[str, Any]:
    """
    ì‚¬ì „ ê²€ìƒ‰ëœ contentì™€ examplesë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    Query expansionì„ í†µí•´ ì–»ì€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸° ì •ë³´ë¡œ í™œìš©í•˜ë©°,
    í•˜ìœ„ ì§ˆë¬¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ì„œ ì´ì „ ë‹¨ê³„ì˜ ì§ˆë¬¸-ë‹µë³€ì„ ëˆ„ì í•©ë‹ˆë‹¤.

    Args:
        original_query: ì›ë³¸ ë³µì¡í•œ ì§ˆë¬¸
        content_docs: ì‚¬ì „ ê²€ìƒ‰ëœ content ë¬¸ì„œë“¤
        example_docs: ì‚¬ì „ ê²€ìƒ‰ëœ example ë¬¸ì„œë“¤
        retrieval_type: ê²€ìƒ‰ íƒ€ì…
        hybrid_weights: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        max_subquestions: ìµœëŒ€ í•˜ìœ„ ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        ìµœì¢… ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    print(f"ğŸ” Processing complex query with expansion: {original_query}")
    print(f"ğŸ“Š Initial resources: {len(content_docs)} content docs, {len(example_docs)} example docs")

    try:
        # 1. ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì‚¬ì „ ê²€ìƒ‰ëœ ë°ì´í„° í™œìš©)
        print("ğŸ“ Step 1: Building initial context from pre-retrieved data...")
        initial_context_parts = []

        if content_docs:
            content_texts = []
            for doc in content_docs:
                if hasattr(doc, "page_content"):
                    content_texts.append(doc.page_content)
                else:
                    content_texts.append(str(doc))
            
            if content_texts:
                initial_context_parts.append(
                    "Available Content:\n" + "\n".join(content_texts[:3])
                )  # Limit for context size

        if example_docs:
            example_texts = []
            for doc in example_docs:
                if isinstance(doc, dict):
                    example_texts.append(doc.get("page_content", str(doc)))
                else:
                    example_texts.append(str(doc))
            
            if example_texts:
                initial_context_parts.append(
                    "Available Examples:\n" + "\n".join(example_texts[:2])
                )  # Limit for context size

        initial_context = "\n\n".join(initial_context_parts)
        print(f"   ğŸ“ Initial context length: {len(initial_context)} characters")

        # 2. ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì§ˆë¬¸ ë¶„í•´
        print("ğŸ”§ Step 2: Decomposing query with context awareness...")

        try:
            response = utils.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": f"""You are an expert in semiconductor physics who excels at breaking down complex questions into simpler, manageable sub-questions.

Given a complex question and available context (content documents and examples), break it down into {max_subquestions} or fewer sub-questions that:
1. Are simpler and more focused than the original question
2. Build upon each other logically 
3. Leverage the available context and examples effectively
4. When answered together, provide comprehensive information to solve the original question
5. Are specific to semiconductor physics domain

The available context includes:
- Technical content documents with theoretical background
- Example documents with practical applications and calculations

Format your response as a numbered list:
1. [First sub-question]
2. [Second sub-question]
...

Respond with ONLY the numbered list of sub-questions.""",
                    },
                    {
                        "role": "user",
                        "content": f"""Complex Question: {original_query}

Available Context:
{initial_context}

Break down this question into focused sub-questions that can effectively leverage the available context.""",
                    },
                ],
                max_tokens=1000,
                temperature=0.3,
            )

            response_text = response.choices[0].message.content.strip()
            subquestions = []
            lines = response_text.split("\n")

            for line in lines:
                line = line.strip()
                if line and (line[0].isdigit() or line.startswith("-")):
                    if ". " in line:
                        question = line.split(". ", 1)[1].strip()
                    elif "- " in line:
                        question = line.split("- ", 1)[1].strip()
                    else:
                        question = line.strip()

                    if question and len(question) > 10:
                        subquestions.append(question)

            if not subquestions:
                print("   âš ï¸ Warning: No context-aware sub-questions generated, using fallback")
                subquestions = [
                    f"What are the fundamental concepts related to: {original_query}?",
                    f"How can the available examples help understand: {original_query}?",
                    f"What are the key factors that influence: {original_query}?",
                ]

            subquestions = subquestions[:max_subquestions]
            print(f"   âœ… Generated {len(subquestions)} context-aware sub-questions")

        except Exception as e:
            print(f"   âŒ Error in context-aware query decomposition: {e}")
            print("   ğŸ”„ Falling back to standard decomposition...")
            subquestions = decompose_query(original_query, max_subquestions)

        if not subquestions:
            print("   âŒ Critical: No sub-questions could be generated")
            return {
                "original_query": original_query,
                "subquestions": [original_query],
                "subquestion_results": [],
                "final_answer": f"Unable to decompose query with expansion: {original_query}",
                "combined_context": initial_context,
                "all_context_docs": content_docs,
                "cumulative_qa_context": "",
                "processing_summary": "Failed to decompose query",
            }

        print(f"ğŸ“‹ Final sub-questions for processing:")
        for i, sq in enumerate(subquestions, 1):
            print(f"  {i}. {sq}")

        # 3. ìˆœì°¨ì  í•˜ìœ„ ì§ˆë¬¸ ì²˜ë¦¬ (ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        print("âš¡ Step 3: Processing sub-questions sequentially with initial context...")
        subquestion_results = []
        
        # ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²« ë²ˆì§¸ ë‹¨ê³„ì˜ "ì´ì „ ê²°ê³¼"ë¡œ í™œìš©
        initial_result = {
            "question": "Initial Context (Pre-retrieved Content & Examples)",
            "answer": initial_context,
        } if initial_context else None

        for i, subquestion in enumerate(subquestions, 1):
            try:
                print(f"Processing sub-question {i}/{len(subquestions)}: {subquestion}")

                # ì´ì „ ê²°ê³¼ë“¤ + ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ í¬í•¨
                previous_results_with_context = []
                if initial_result and i == 1:
                    # ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œë§Œ ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ í¬í•¨
                    previous_results_with_context.append(initial_result)
                    print(f"   ğŸ“š Including initial context for first step")
                
                # ëª¨ë“  ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ ëˆ„ì 
                previous_results_with_context.extend(subquestion_results)
                
                print(f"   ğŸ“Š Total context sources: {len(previous_results_with_context)}")

                # í•˜ìœ„ ì§ˆë¬¸ ì²˜ë¦¬ (ìš”êµ¬ì‚¬í•­ 2: ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©)
                result = process_subquestion(
                    subquestion,
                    retrieval_type,
                    hybrid_weights,
                    previous_results=previous_results_with_context,
                )

                subquestion_results.append(result)

                print(f"   âœ… Step {i} completed successfully")
                # print(f"   ğŸ“ˆ Answer length: {len(result.get('answer', ''))} characters")

            except Exception as e:
                print(f"   âŒ Error processing Step {i}: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ê²°ê³¼ ì¶”ê°€
                error_result = {
                    "question": subquestion,
                    "retrieved_context": "",
                    "previous_context": [],
                    "full_context": "",
                    "answer": f"Error processing this sub-question: {str(e)}",
                    "explanation": "",
                    "context_docs": [],
                    "step_number": i,
                }
                subquestion_results.append(error_result)

        # 4. ìµœì¢… ë‹µë³€ ì¢…í•©
        print("ğŸ¯ Step 4: Aggregating sequential results into final answer...")
        try:
            final_answer = aggregate_subquestion_results(
                original_query, subquestion_results
            )
            print(f"   âœ… Final answer generated (length: {len(final_answer)} characters)")
        except Exception as e:
            print(f"   âŒ Error in final aggregation: {e}")
            print("   ğŸ”„ Using fallback aggregation...")
            # í´ë°±: ê°„ë‹¨í•œ ë‹µë³€ ì¡°í•©
            answers = [
                result["answer"] for result in subquestion_results if result.get("answer")
            ]
            final_answer = (
                f"Based on sequential analysis with expansion:\n\n"
                + "\n\n".join(answers)
            )

        # 5. ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í†µí•©
        print("ğŸ“š Step 5: Consolidating all contexts...")
        all_retrieved_contexts = []
        all_context_docs = list(content_docs)  # ì´ˆê¸° content ë¬¸ì„œë“¤ë¡œ ì‹œì‘

        # ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if initial_context:
            all_retrieved_contexts.append(f"=== Initial Context ===\n{initial_context}")

        # ê° ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        for i, result in enumerate(subquestion_results, 1):
            if result.get("retrieved_context"):
                all_retrieved_contexts.append(
                    f"=== Step {i} Retrieved Context ===\n{result['retrieved_context']}"
                )
            if result.get("context_docs"):
                all_context_docs.extend(result["context_docs"])

        combined_context = "\n\n".join(all_retrieved_contexts)

        # 6. ëˆ„ì  Q&A ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì „ì²´ ì§„í–‰ ê³¼ì • ì¶”ì ìš©)
        print("ğŸ“ Step 6: Building cumulative Q&A context...")
        cumulative_qa_parts = []
        
        if initial_context:
            cumulative_qa_parts.append(f"Initial Context:\n{initial_context}")
        for i, result in enumerate(subquestion_results, 1):
            cumulative_qa_parts.append(
                f"Step {i} Q: {result['question']}\n"
                f"Step {i} A: {result['answer']}"
            )
        
        cumulative_qa_context = "\n\n".join(cumulative_qa_parts)

        print("âœ… Complex query processing with expansion completed successfully")
        print(f"ğŸ“ˆ Processing summary:")
        print(f"   - Original query: {original_query}")
        print(f"   - Sub-questions processed: {len(subquestion_results)}")
        print(f"   - Total context docs: {len(all_context_docs)}")
        print(f"   - Final answer length: {len(final_answer)} characters")

        return {
            "original_query": original_query,
            "subquestions": subquestions,
            "subquestion_results": subquestion_results,
            "final_answer": final_answer,
            "combined_context": combined_context,
            "all_context_docs": all_context_docs,
            "cumulative_qa_context": cumulative_qa_context,
            "processing_summary": f"Processed {len(subquestions)} sub-questions with expansion context (content: {len(content_docs)}, examples: {len(example_docs)})",
        }

    except Exception as e:
        print(f"ğŸ’¥ Critical error in complex query processing with expansion: {e}")
        import traceback
        traceback.print_exc()
        
        # ìµœì¢… í´ë°±
        return {
            "original_query": original_query,
            "subquestions": [original_query],
            "subquestion_results": [],
            "final_answer": f"Error processing complex query with expansion: {str(e)}. Please try rephrasing your question.",
            "combined_context": "",
            "all_context_docs": content_docs,
            "cumulative_qa_context": "",
            "processing_summary": f"Error occurred during expansion processing: {str(e)}",
        }
